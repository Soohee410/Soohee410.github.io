I"<p>오늘은 <code class="language-plaintext highlighter-rouge">Embedding Projector</code>를 이용해서 임베딩 벡터를 시각화해보겠습니다! 준비물은 임베딩하고 난 후의 metadata.tsv와 tensor.tsv 두 데이터가 필요한데요. 이 데이터들은 다음과 같이 얻을 수 있습니다! 먼저 저는 <a href="https://github.com/e9t/nsmc">네이버 영화 리뷰</a>를 형태소 분석한 후에, 이 데이터를 다음과 같이 Word2Vec을 훈련시키고 이 모델을 ‘naver_w2v’라는 이름으로 저장했습니다.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">Word2Vec</span>  
<span class="n">model</span> <span class="o">=</span> <span class="n">Word2Vec</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">window</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">min_count</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">sg</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>  

<span class="kn">from</span> <span class="nn">gensim.models</span> <span class="kn">import</span> <span class="n">KeyedVectors</span>  
<span class="n">model</span><span class="p">.</span><span class="n">wv</span><span class="p">.</span><span class="n">save_word2vec_format</span><span class="p">(</span><span class="s">'naver_w2v'</span><span class="p">)</span>
</code></pre></div></div>

<p>이후, 다음과 같이 입력하면, <strong>naver_w2v_metadata.tsv</strong>와 <strong>naver_w2v_tensor.tsv</strong>라는 파일이 해당 폴더 내에 저장될 것입니다. 정말 간단하죠?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="err">!</span><span class="n">python</span> <span class="o">-</span><span class="n">m</span> <span class="n">gensim</span><span class="p">.</span><span class="n">scripts</span><span class="p">.</span><span class="n">word2vec2tensor</span> <span class="o">--</span><span class="nb">input</span> <span class="n">naver_w2v</span> <span class="o">--</span><span class="n">output</span> <span class="n">naver_w2v</span>
</code></pre></div></div>

<hr />

<p>이제 <a href="https://projector.tensorflow.org/">Embedding Projector</a> 사이트로 들어가서, 왼쪽에 존재하는 <strong>load</strong> 버튼을 클릭하면 다음과 같은 창이 나타납니다. 여기서 위에다가 tensor.tsv파일을, 아래에는 metadata.tsv파일을 로드합니다.</p>

<p><img src="/assets/img/embed_img0.PNG" width="650px" /></p>

<p><br />
먼저 <strong>감독</strong>이라는 단어를 검색해보았는데요. 다음과 같이 3차원의 구조가 나타나고, 이를 원하는 방향에서 볼 수 있도록 회전시킬 수 있습니다. 유명한 한국 감독들의 이름이 가까이 나타나는 것을 확인할 수 있네요!</p>

<p><img src="/assets/img/embed_img5.gif" width="600px" /></p>

<p><br />
한국 배우의 이름을 검색하면 어떨까요? <strong>최민식</strong>을 Word2Vec 모델에서 검색하면 다음과 같이 한국 배우들의 이름이 가까이 나타났었는데요.</p>

<p><img src="/assets/img/embed_img6.PNG" width="750px" /></p>

<p><br />
Embedding Projector로 시각화하면 마찬가지로 다음과 같이 한국 영화배우들의 이름이 가까이 나타나는 것을 볼 수 있습니다. 최민식이라는 배우를 충분히 학습할 만큼 리뷰 데이터에 내용이 많지 않은 것을 감안할 때, 임베딩 결과가 나름 합리적으로 보입니다.</p>

<p><img src="/assets/img/embed_img2.png" width="600px" /></p>

<p><br />
이번에는 <strong>노잼</strong>을 검색한 결과입니다. 영화에 대한 부정적인 단어들이 가까이 나타나는 것을 볼 수 있습니다. 대표적인 부정적 단어인 만큼, 학습하기도 쉽고 무조건 잘 학습되어야 하는 단어인 것 같습니다.</p>

<p><img src="/assets/img/embed_img3.png" width="550px" /></p>

<p><br />
다음은 <strong>대박</strong>을 검색한 결과입니다. 대체로 영화에 대한 긍정적인 단어들이 가까이 나타나는 것을 볼 수 있습니다. 이 단어는 리뷰 내용을 긍정으로 분류할 때 큰 역할할 것으로 보입니다.</p>

<p><img src="/assets/img/embed_img4.png" width="550px" /></p>

<p><br /></p>

<p>저는 이 시각화 도구를 처음 접하고 재미있어서 이것저것 많이 검색해보곤 했는데요ㅎㅎ 빠르고 간단하게 임베딩 결과를 한눈에 보고 싶을 때, Embedding Projector를 이용하면 확실히 편리한 것 같습니다!</p>

<p><br /></p>
:ET